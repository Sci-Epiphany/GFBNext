DEVICE          : cuda              # device used for training and evaluation (cpu, cuda, cuda0, cuda1, ...)
SAVE_DIR        : 'output'          # output folder name used for saving the model, logs and inference results

MODEL:
  NAME          : CMNeXt                                            # name of the model you are using
  BACKBONE      : CMNeXt-B4                                         # model variant
  PRETRAINED    : 'checkpoints/pretrained/segformer/mit_b4.pth'     # backbone model's weight 
  RESUME        : ''                                                # checkpoint file 

DATASET:
  NAME          : UrbanLF                                          # dataset name to be trained with (camvid, cityscapes, ade20k)
  # ROOT          : 'data/UrBanLF/real'                              # dataset root path, for real dataset
  ROOT          : 'data/UrBanLF/Syn'                             # dataset root path, for synthetic dataset
  IGNORE_LABEL  : 255
  # MODALS        : ['img'] 
  # MODALS        : ['img', '5_1', '5_2', '5_3', '5_4', '5_6', '5_7', '5_8', '5_9']
  # MODALS        : ['img', '1_1', '1_5', '1_9', '2_2', '2_5', '2_8', '3_3', '3_5', '3_7', '4_4', '4_5', '4_6', '5_1', '5_2', '5_3', '5_4', '5_6', '5_7', '5_8', '5_9', '6_4', '6_5', '6_6', '7_3', '7_5', '7_7', '8_2', '8_5', '8_8', '9_1', '9_5', '9_9']
  MODALS        : ['img', '1_1', '1_2', '1_3', '1_4', '1_5', '1_6', '1_7', '1_8', '1_9', '2_1', '2_2', '2_3', '2_4', '2_5', '2_6', '2_7', '2_8', '2_9', '3_1', '3_2', '3_3', '3_4', '3_5', '3_6', '3_7', '3_8', '3_9', '4_1', '4_2', '4_3', '4_4', '4_5', '4_6', '4_7', '4_8', '4_9', '5_1', '5_2', '5_3', '5_4', '5_6', '5_7', '5_8', '5_9', '6_1', '6_2', '6_3', '6_4', '6_5', '6_6', '6_7', '6_8', '6_9', '7_1', '7_2', '7_3', '7_4', '7_5', '7_6', '7_7', '7_8', '7_9', '8_1', '8_2', '8_3', '8_4', '8_5', '8_6', '8_7', '8_8', '8_9', '9_1', '9_2', '9_3', '9_4', '9_5', '9_6', '9_7', '9_8', '9_9']

TRAIN:
  IMAGE_SIZE    : [480, 640]      # training image size in (h, w)
  BATCH_SIZE    : 2               # batch size used to train
  EPOCHS        : 500             # number of epochs to train
  EVAL_START    : 300             # evaluation interval start
  EVAL_INTERVAL : 1               # evaluation interval during training
  AMP           : false           # use AMP in training
  DDP           : true            # use DDP training

LOSS:
  NAME          : OhemCrossEntropy          # loss function name
  CLS_WEIGHTS   : false            # use class weights in loss calculation

OPTIMIZER:
  NAME          : adamw           # optimizer name
  LR            : 0.00006         # initial learning rate used in optimizer
  WEIGHT_DECAY  : 0.01            # decay rate used in optimizer 

SCHEDULER:
  NAME          : warmuppolylr    # scheduler name
  POWER         : 0.9             # scheduler power
  WARMUP        : 10              # warmup epochs used in scheduler
  WARMUP_RATIO  : 0.1             # warmup ratio
  

EVAL:
  # MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_real_rgblf1.pth'
  # MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_real_rgblf8.pth'
  # MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_real_rgblf33.pth'
  # MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_real_rgblf80.pth'

  # MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_syn_rgblf1.pth'
  # MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_syn_rgblf8.pth'
  # MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_syn_rgblf33.pth'
  MODEL_PATH    : 'output/UrbanLF/cmnext_b4_urbanlf_syn_rgblf80.pth'
  IMAGE_SIZE    : [480, 640]      # eval image size in (h, w)            
  BATCH_SIZE    : 2               # batch size used to train
  MSF: 
    ENABLE      : false                                   # multi-scale and flip evaluation  
    FLIP        : true                                    # use flip in evaluation  
    SCALES      : [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]       # scales used in MSF evaluation                
